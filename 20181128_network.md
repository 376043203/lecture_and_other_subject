# Understanding Generative Adversarial Networks  
## Prof. David Tse  
David Tse received the B.A.Sc. degree in systems design engineering from University of Waterloo in 1989, and the M.S. and Ph.D. degrees in electrical engineering from Massachusetts Institute of Technology in 1991 and 1994 respectively. From 1995 to 2014, he was on the faculty of the University of California at Berkeley. 

Generative Adversarial Networks (GANs) are a novel approach to the age-old problem of learning a probability model from data. Many GAN architectures with different optimization metrics have been introduced recently. To understand the many design and analysis issues surrounding GANs , we ask a basic question: what is a natural GAN architecture to learn a high-dimensional Gaussian distribution? Answering that question leads to an exploration of several fascinating issues, such as the connection between supervised and unsupervised learning, the generalizability of GANs and the stability of their training.  

In GANs design approach, he firstly assumes the model can get good population solution, which is for initial formulation. It also has get generation, for final formulation, and designed freely. In order to formulate GANs, you have to know the differences of unsupervised learning and supervised learning, and he mentions way to reduce unsupervised problems to supervised problems, using coupling to produce every possible pairs of number, choosing the easiest one to continue supervised learning.   

Then he create a GANs problem with easier dual problem and ensure the optimization for all conditions. The result and stability are good. Through his lecture, I have a deeper understanding about what I learned before about data learning, and also, Dr.Tse gives a good example to identify the problem and explore the solution, which is important for my future study. the combination of supervised learning and unsupervised learning and the introduction of GANs provides me with more inspirations about my studying fields.  


